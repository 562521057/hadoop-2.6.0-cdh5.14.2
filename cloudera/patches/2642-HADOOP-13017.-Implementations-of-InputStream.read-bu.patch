From ae4d2241d840a40f87c7a9f116c9b4647de50e55 Mon Sep 17 00:00:00 2001
From: John Zhuge <jzhuge@cloudera.com>
Date: Wed, 13 Sep 2017 11:07:20 -0700
Subject: [PATCH 2642/2748] HADOOP-13017. Implementations of
 InputStream.read(buffer, offset, bytes) to exit 0
 if bytes==0. Contributed by Steve Loughran.

(cherry picked from commit 0bdd263d82a4510f16df49238d57c9f78ac28ae7)

Conflicts:
	hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
	hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
	hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java

Change-Id: Id57e59c1c163e78bc90fb21f075970f5ca7bfe0e
---
 .../java/org/apache/hadoop/fs/HarFileSystem.java   |    3 +++
 .../apache/hadoop/security/SaslInputStream.java    |    5 ++++-
 .../org/apache/hadoop/security/SaslRpcClient.java  |    3 +++
 .../org/apache/hadoop/util/LimitInputStream.java   |    3 +++
 .../apache/hadoop/hdfs/web/WebHdfsFileSystem.java  |    3 +++
 .../hadoop/tools/util/ThrottledInputStream.java    |    3 +++
 .../fs/swift/http/HttpInputStreamWithRelease.java  |    3 +++
 .../fs/swift/snative/SwiftNativeInputStream.java   |    3 +++
 8 files changed, 25 insertions(+), 1 deletion(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java
index aadcbb1..ee19b28 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java
@@ -973,6 +973,9 @@ public synchronized int read(byte[] b) throws IOException {
       @Override
       public synchronized int read(byte[] b, int offset, int len) 
         throws IOException {
+        if (len == 0) {
+          return 0;
+        }
         int newlen = len;
         int ret = -1;
         if (position + len > end) {
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslInputStream.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslInputStream.java
index 7ee4523..a3d66b9 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslInputStream.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslInputStream.java
@@ -246,6 +246,9 @@ public int read(byte[] b) throws IOException {
    */
   @Override
   public int read(byte[] b, int off, int len) throws IOException {
+    if (len == 0) {
+      return 0;
+    }
     if (!useWrap) {
       return inStream.read(b, off, len);
     }
@@ -378,4 +381,4 @@ public int read(ByteBuffer dst) throws IOException {
     }
     return bytesRead;
   }
-}
\ No newline at end of file
+}
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
index 919aded..9dd436e 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java
@@ -574,6 +574,9 @@ public int read(byte b[]) throws IOException {
 
     @Override
     public int read(byte[] buf, int off, int len) throws IOException {
+      if (len == 0) {
+        return 0;
+      }
       synchronized(unwrappedRpcBuffer) {
         // fill the buffer with the next RPC message
         if (unwrappedRpcBuffer.remaining() == 0) {
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
index c94a517..bd646e0 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java
@@ -74,6 +74,9 @@ public int read() throws IOException {
 
   @Override
   public int read(byte[] b, int off, int len) throws IOException {
+    if (len == 0) {
+      return 0;
+    }
     if (left == 0) {
       return -1;
     }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
index ecf1b2b..44f7b22 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java
@@ -1767,6 +1767,9 @@ int read(byte[] b, int off, int len) throws IOException {
       if (runnerState == RunnerState.CLOSED) {
         throw new IOException("Stream closed");
       }
+      if (len == 0) {
+        return 0;
+      }
 
       // Before the first read, pos and fileLength will be 0 and readBuffer
       // will all be null. They will be initialized once the first connection
diff --git a/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/ThrottledInputStream.java b/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/ThrottledInputStream.java
index fe70608..a33d9bf 100644
--- a/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/ThrottledInputStream.java
+++ b/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/util/ThrottledInputStream.java
@@ -84,6 +84,9 @@ public int read(byte[] b) throws IOException {
   /** @inheritDoc */
   @Override
   public int read(byte[] b, int off, int len) throws IOException {
+    if (len == 0) {
+      return 0;
+    }
     throttle();
     int readLen = rawStream.read(b, off, len);
     if (readLen != -1) {
diff --git a/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/http/HttpInputStreamWithRelease.java b/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/http/HttpInputStreamWithRelease.java
index c75759e..627792c 100644
--- a/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/http/HttpInputStreamWithRelease.java
+++ b/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/http/HttpInputStreamWithRelease.java
@@ -187,6 +187,9 @@ public int read() throws IOException {
   @Override
   public int read(byte[] b, int off, int len) throws IOException {
     SwiftUtils.validateReadArgs(b, off, len);
+    if (len == 0) {
+      return 0;
+    }
     //if the stream is already closed, then report an exception.
     assumeNotReleased();
     //now read in a buffer, reacting differently to different operations
diff --git a/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeInputStream.java b/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeInputStream.java
index 3fd3702..23d8c09 100644
--- a/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeInputStream.java
+++ b/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeInputStream.java
@@ -161,6 +161,9 @@ public synchronized int read() throws IOException {
   public synchronized int read(byte[] b, int off, int len) throws IOException {
     SwiftUtils.debug(LOG, "read(buffer, %d, %d)", off, len);
     SwiftUtils.validateReadArgs(b, off, len);
+    if (len == 0) {
+      return 0;
+    }
     int result = -1;
     try {
       verifyOpen();
-- 
1.7.9.5

