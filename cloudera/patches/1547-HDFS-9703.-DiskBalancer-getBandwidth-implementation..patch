From c7979a58730ed6c06751b222011cd8b25659af92 Mon Sep 17 00:00:00 2001
From: Arpit Agarwal <arp@apache.org>
Date: Mon, 14 Mar 2016 12:57:29 -0700
Subject: [PATCH 1547/2748] HDFS-9703. DiskBalancer: getBandwidth
 implementation. (Contributed by Anu Engineer)

(cherry picked from commit 4f98af41469e36917bb622f60ad50f0f5f2a1c97)

Change-Id: I46530a602e94662d3ab4669ea0cb8a1bb5e1fbd7
---
 .../hadoop/hdfs/server/datanode/DataNode.java      |    6 +++--
 .../hadoop/hdfs/server/datanode/DiskBalancer.java  |   17 +++++++++++++
 .../server/diskbalancer/TestDiskBalancerRPC.java   |   26 ++++++++++++--------
 3 files changed, 37 insertions(+), 12 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
index 2b462b4..d86d8cc 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
@@ -917,7 +917,7 @@ private synchronized void shutdownDirectoryScanner() {
    * @param  data - FSDataSet
    * @param conf - Config
    */
-  private synchronized void initDiskBalancer(FsDatasetSpi data,
+  private void initDiskBalancer(FsDatasetSpi data,
                                              Configuration conf) {
     if (this.diskBalancer != null) {
       return;
@@ -931,7 +931,7 @@ private synchronized void initDiskBalancer(FsDatasetSpi data,
   /**
    * Shutdown disk balancer.
    */
-  private synchronized void shutdownDiskBalancer() {
+  private  void shutdownDiskBalancer() {
     if (this.diskBalancer != null) {
       this.diskBalancer.shutdown();
       this.diskBalancer = null;
@@ -3088,6 +3088,8 @@ public String getDiskBalancerSetting(String key) throws IOException {
     switch (key) {
     case DiskBalancerConstants.DISKBALANCER_VOLUME_NAME:
       return this.diskBalancer.getVolumeNames();
+    case DiskBalancerConstants.DISKBALANCER_BANDWIDTH :
+      return Long.toString(this.diskBalancer.getBandwidth());
     default:
       LOG.error("Disk Balancer - Unknown key in get balancer setting. Key: " +
           key);
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
index 9e41d2e..d1bc1f1 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
@@ -73,6 +73,7 @@
   private Future future;
   private String planID;
   private DiskBalancerWorkStatus.Result currentResult;
+  private long bandwidth;
 
   /**
    * Constructs a Disk Balancer object. This object takes care of reading a
@@ -159,6 +160,7 @@ public void submitPlan(String planID, long planVersion, String plan,
       createWorkPlan(nodePlan);
       this.planID = planID;
       this.currentResult = Result.PLAN_UNDER_PROGRESS;
+      this.bandwidth = bandwidth;
       executePlan();
     } finally {
       lock.unlock();
@@ -248,6 +250,21 @@ public String getVolumeNames() throws DiskBalancerException {
     }
   }
 
+  /**
+   * Returns the current bandwidth.
+   *
+   * @return string representation of bandwidth.
+   * @throws DiskBalancerException
+   */
+  public long getBandwidth() throws DiskBalancerException {
+    lock.lock();
+    try {
+      checkDiskBalancerEnabled();
+      return this.bandwidth;
+    } finally {
+      lock.unlock();
+    }
+  }
 
   /**
    * Throws if Disk balancer is disabled.
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
index 37a6216..9cd41c2 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
@@ -187,6 +187,22 @@ public void testGetDiskBalancerInvalidSetting() throws Exception {
     dataNode.getDiskBalancerSetting(invalidSetting);
   }
 
+  @Test
+  public void testgetDiskBalancerBandwidth() throws Exception {
+    RpcTestHelper rpcTestHelper = new RpcTestHelper().invoke();
+    DataNode dataNode = rpcTestHelper.getDataNode();
+    String planHash = rpcTestHelper.getPlanHash();
+    int planVersion = rpcTestHelper.getPlanVersion();
+    NodePlan plan = rpcTestHelper.getPlan();
+
+    dataNode.submitDiskBalancerPlan(planHash, planVersion, 10, plan.toJson());
+    String bandwidthString = dataNode.getDiskBalancerSetting(
+        DiskBalancerConstants.DISKBALANCER_BANDWIDTH);
+    long value = Long.decode(bandwidthString);
+    Assert.assertEquals(10L, value);
+  }
+
+
 
   @Test
   public void testQueryPlan() throws Exception {
@@ -211,16 +227,6 @@ public void testQueryPlanWithoutSubmit() throws Exception {
     Assert.assertTrue(status.getResult() == NO_PLAN);
   }
 
-  @Test
-  public void testGetDiskBalancerSetting() throws Exception {
-    final int dnIndex = 0;
-    DataNode dataNode = cluster.getDataNodes().get(dnIndex);
-    thrown.expect(DiskBalancerException.class);
-    thrown.expect(new
-        ResultVerifier(Result.UNKNOWN_KEY));
-    dataNode.getDiskBalancerSetting(
-        DiskBalancerConstants.DISKBALANCER_BANDWIDTH);
-  }
 
   private class RpcTestHelper {
     private NodePlan plan;
-- 
1.7.9.5

