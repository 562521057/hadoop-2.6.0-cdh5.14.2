From 0b6ed491bc4bb29221a263d6ff0ce3e8ad313d0f Mon Sep 17 00:00:00 2001
From: Zhe Zhang <zhz@apache.org>
Date: Wed, 17 Feb 2016 13:30:50 -0800
Subject: [PATCH 1245/2748] HDFS-9799. Reimplement getCurrentTrashDir to
 remove incompatibility. (zhz)

Conflicts:
	hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
	hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
	hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt

Change-Id: I4c443b55b0f489c35fa1fff5c57b3501a6d46239
---
 .../main/java/org/apache/hadoop/fs/FileSystem.java |   41 ++++++------
 .../org/apache/hadoop/fs/FilterFileSystem.java     |    5 +-
 .../java/org/apache/hadoop/fs/TrashPolicy.java     |    2 +-
 .../org/apache/hadoop/fs/TrashPolicyDefault.java   |    9 +--
 .../apache/hadoop/hdfs/DistributedFileSystem.java  |   68 +++++++++++---------
 5 files changed, 64 insertions(+), 61 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
index 527fa8b..3d4221b 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
@@ -2598,9 +2598,8 @@ public void removeXAttr(Path path, String name) throws IOException {
    *
    * @param path the trash root of the path to be determined.
    * @return the default implementation returns "/user/$USER/.Trash".
-   * @throws IOException
    */
-  public Path getTrashRoot(Path path) throws IOException {
+  public Path getTrashRoot(Path path) {
     return this.makeQualified(new Path(getHomeDirectory().toUri().getPath(),
         TRASH_PREFIX));
   }
@@ -2612,29 +2611,31 @@ public Path getTrashRoot(Path path) throws IOException {
    * @return all the trash root directories.
    *         Default FileSystem returns .Trash under users' home directories if
    *         /user/$USER/.Trash exists.
-   * @throws IOException
    */
-  public Collection<FileStatus> getTrashRoots(boolean allUsers)
-      throws IOException {
+  public Collection<FileStatus> getTrashRoots(boolean allUsers) {
     Path userHome = new Path(getHomeDirectory().toUri().getPath());
-    List<FileStatus> ret = new ArrayList<FileStatus>();
-    if (!allUsers) {
-      Path userTrash = new Path(userHome, TRASH_PREFIX);
-      if (exists(userTrash)) {
-        ret.add(getFileStatus(userTrash));
-      }
-    } else {
-      Path homeParent = userHome.getParent();
-      if (exists(homeParent)) {
-        FileStatus[] candidates = listStatus(homeParent);
-        for (FileStatus candidate : candidates) {
-          Path userTrash = new Path(candidate.getPath(), TRASH_PREFIX);
-          if (exists(userTrash)) {
-            candidate.setPath(userTrash);
-            ret.add(candidate);
+    List<FileStatus> ret = new ArrayList<>();
+    try {
+      if (!allUsers) {
+        Path userTrash = new Path(userHome, TRASH_PREFIX);
+        if (exists(userTrash)) {
+          ret.add(getFileStatus(userTrash));
+        }
+      } else {
+        Path homeParent = userHome.getParent();
+        if (exists(homeParent)) {
+          FileStatus[] candidates = listStatus(homeParent);
+          for (FileStatus candidate : candidates) {
+            Path userTrash = new Path(candidate.getPath(), TRASH_PREFIX);
+            if (exists(userTrash)) {
+              candidate.setPath(userTrash);
+              ret.add(candidate);
+            }
           }
         }
       }
+    } catch (IOException e) {
+      LOG.warn("Cannot get all trash roots", e);
     }
     return ret;
   }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
index ca9e4da..a8bff3f 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
@@ -617,13 +617,12 @@ public void removeXAttr(Path path, String name) throws IOException {
   }
 
   @Override
-  public Path getTrashRoot(Path path) throws IOException {
+  public Path getTrashRoot(Path path) {
     return fs.getTrashRoot(path);
   }
 
   @Override
-  public Collection<FileStatus> getTrashRoots(boolean allUsers)
-      throws IOException {
+  public Collection<FileStatus> getTrashRoots(boolean allUsers) {
     return fs.getTrashRoots(allUsers);
   }
 }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
index 1d901c1..92a4d1f 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
@@ -89,7 +89,7 @@ public void initialize(Configuration conf, FileSystem fs) throws IOException{
    * It returns the trash location correctly for the path specified no matter
    * the path is in encryption zone or not.
    */
-  public abstract Path getCurrentTrashDir() throws IOException;
+  public abstract Path getCurrentTrashDir();
 
   /**
    * Get the current trash directory for path specified based on the Trash
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
index efc0072..28db53f 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
@@ -199,7 +199,7 @@ public void deleteCheckpoint() throws IOException {
   }
 
   @Override
-  public Path getCurrentTrashDir() throws IOException {
+  public Path getCurrentTrashDir() {
     return new Path(fs.getTrashRoot(null), CURRENT);
   }
 
@@ -249,12 +249,7 @@ public void run() {
           now = Time.now();
           if (now >= end) {
             Collection<FileStatus> trashRoots;
-            try {
-              trashRoots = fs.getTrashRoots(true);      // list all home dirs
-            } catch (IOException e) {
-              LOG.warn("Trash can't list all trash roots: "+e+" Sleeping.");
-              continue;
-            }
+            trashRoots = fs.getTrashRoots(true);      // list all trash dirs
 
             for (FileStatus trashRoot : trashRoots) {   // dump each trash
               if (!trashRoot.isDirectory())
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
index 83adda1..fd95bcc 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
@@ -2163,31 +2163,34 @@ public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)
     return dfs.getInotifyEventStream(lastReadTxid);
   }
 
-
   /**
    * Get the root directory of Trash for a path in HDFS.
    * 1. File in encryption zone returns /ez1/.Trash/username
-   * 2. File not in encryption zone returns /users/username/.Trash
+   * 2. File not in encryption zone, or encountered exception when checking
+   *    the encryption zone of the path, returns /users/username/.Trash
    * Caller appends either Current or checkpoint timestamp for trash destination
    * @param path the trash root of the path to be determined.
    * @return trash root
-   * @throws IOException
    */
   @Override
-  public Path getTrashRoot(Path path) throws IOException {
-    if ((path == null) || !dfs.isHDFSEncryptionEnabled()) {
+  public Path getTrashRoot(Path path) {
+    if ((path == null) || path.isRoot() || !dfs.isHDFSEncryptionEnabled()) {
       return super.getTrashRoot(path);
     }
 
-    String absSrc = path.toUri().getPath();
-    EncryptionZone ez = dfs.getEZForPath(absSrc);
-    if ((ez != null) && !ez.getPath().equals(absSrc)) {
-      return this.makeQualified(
-          new Path(ez.getPath() + "/" + FileSystem.TRASH_PREFIX +
-              dfs.ugi.getShortUserName()));
-    } else {
-      return super.getTrashRoot(path);
+    String parentSrc = path.getParent().toUri().getPath();
+    try {
+      EncryptionZone ez = dfs.getEZForPath(parentSrc);
+      if ((ez != null)) {
+        return this.makeQualified(
+            new Path(ez.getPath() + "/" + FileSystem.TRASH_PREFIX +
+                dfs.ugi.getShortUserName()));
+      }
+    } catch (IOException e) {
+      DFSClient.LOG.warn("Exception in checking the encryption zone for the " +
+          "path " + parentSrc + ". " + e.getMessage());
     }
+    return super.getTrashRoot(path);
   }
 
   /**
@@ -2195,32 +2198,37 @@ public Path getTrashRoot(Path path) throws IOException {
    * 1. File deleted from non-encryption zone /user/username/.Trash
    * 2. File deleted from encryption zones
    *    e.g., ez1 rooted at /ez1 has its trash root at /ez1/.Trash/$USER
-   * @allUsers return trashRoots of all users if true, used by emptier
+   * @param allUsers return trashRoots of all users if true, used by emptier
    * @return trash roots of HDFS
-   * @throws IOException
    */
   @Override
-  public Collection<FileStatus> getTrashRoots(boolean allUsers) throws IOException {
-    List<FileStatus> ret = new ArrayList<FileStatus>();
+  public Collection<FileStatus> getTrashRoots(boolean allUsers) {
+    List<FileStatus> ret = new ArrayList<>();
     // Get normal trash roots
     ret.addAll(super.getTrashRoots(allUsers));
 
-    // Get EZ Trash roots
-    final RemoteIterator<EncryptionZone> it = dfs.listEncryptionZones();
-    while (it.hasNext()) {
-      Path ezTrashRoot = new Path(it.next().getPath(), FileSystem.TRASH_PREFIX);
-      if (allUsers) {
-        for (FileStatus candidate : listStatus(ezTrashRoot)) {
-          if (exists(candidate.getPath())) {
-            ret.add(candidate);
+    try {
+      // Get EZ Trash roots
+      final RemoteIterator<EncryptionZone> it = dfs.listEncryptionZones();
+      while (it.hasNext()) {
+        Path ezTrashRoot = new Path(it.next().getPath(),
+            FileSystem.TRASH_PREFIX);
+        if (allUsers) {
+          for (FileStatus candidate : listStatus(ezTrashRoot)) {
+            if (exists(candidate.getPath())) {
+              ret.add(candidate);
+            }
+          }
+        } else {
+          Path userTrash = new Path(ezTrashRoot, System.getProperty(
+              "user.name"));
+          if (exists(userTrash)) {
+            ret.add(getFileStatus(userTrash));
           }
-        }
-      } else {
-        Path userTrash = new Path(ezTrashRoot, System.getProperty("user.name"));
-        if (exists(userTrash)) {
-          ret.add(getFileStatus(userTrash));
         }
       }
+    } catch (IOException e){
+      DFSClient.LOG.warn("Cannot get all encrypted trash roots", e);
     }
     return ret;
   }
-- 
1.7.9.5

