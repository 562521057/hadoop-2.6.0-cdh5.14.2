From 295e2b17c9a6353fc39fc1ebedfe839b887a2e46 Mon Sep 17 00:00:00 2001
From: Mingliang Liu <liuml07@apache.org>
Date: Mon, 13 Mar 2017 15:19:06 -0700
Subject: [PATCH 2409/2748] HADOOP-14170. FileSystemContractBaseTest is not
 cleaning up test directory clearly. Contributed
 by Mingliang Liu

(cherry picked from commit ed0d426a88b23965e4188188258a909aa866f012)

Conflicts:
	hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
	hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java

Change-Id: Ibee531274c9fb292887465823271a2ca62f4ab9e
---
 .../hadoop/fs/FileSystemContractBaseTest.java      |  199 ++++++++++++--------
 .../hadoop/fs/s3a/ITestS3AFileSystemContract.java  |   44 ++---
 2 files changed, 129 insertions(+), 114 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
index 52489d2..17074d8 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
@@ -24,8 +24,9 @@
 
 import junit.framework.TestCase;
 
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.security.AccessControlException;
@@ -45,8 +46,8 @@
  * </p>
  */
 public abstract class FileSystemContractBaseTest extends TestCase {
-  private static final Log LOG =
-    LogFactory.getLog(FileSystemContractBaseTest.class);
+  private static final Logger LOG =
+      LoggerFactory.getLogger(FileSystemContractBaseTest.class);
 
   protected final static String TEST_UMASK = "062";
   protected FileSystem fs;
@@ -56,10 +57,13 @@
   protected void tearDown() throws Exception {
     if (fs != null) {
       // some cases use this absolute path
-      cleanupDir(path("/test"));
-      // others use this relative path
-      cleanupDir(path("test"));
+      if (rootDirTestEnabled()) {
+        cleanupDir(path("/FileSystemContractBaseTest"));
+      }
+      // others use this relative path against test base directory
+      cleanupDir(getTestBaseDir());
     }
+    super.tearDown();
   }
 
   private void cleanupDir(Path p) {
@@ -72,7 +76,27 @@ private void cleanupDir(Path p) {
       LOG.error("Error deleting test dir: " + p, e);
     }
   }
-  
+
+  /**
+   * Test base directory for resolving relative test paths.
+   *
+   * The default value is /user/$USER/FileSystemContractBaseTest. Subclass may
+   * set specific test base directory.
+   */
+  protected Path getTestBaseDir() {
+    return new Path(fs.getWorkingDirectory(), "FileSystemContractBaseTest");
+  }
+
+  /**
+   * For absolute path return the fully qualified path while for relative path
+   * return the fully qualified path against {@link #getTestBaseDir()}.
+   */
+  protected final Path path(String pathString) {
+    Path p = new Path(pathString).makeQualified(fs.getUri(), getTestBaseDir());
+    LOG.info("Resolving {} -> {}", pathString, p);
+    return p;
+  }
+
   protected int getBlockSize() {
     return 1024;
   }
@@ -85,6 +109,17 @@ protected boolean renameSupported() {
     return true;
   }
 
+  /**
+   * Override this if the filesystem does not enable testing root directories.
+   *
+   * If this returns true, the test will create and delete test directories and
+   * files under root directory, which may have side effects, e.g. fail tests
+   * with PermissionDenied exceptions.
+   */
+  protected boolean rootDirTestEnabled() {
+    return true;
+  }
+
   public void testFsStatus() throws Exception {
     FsStatus fsStatus = fs.getStatus();
     assertNotNull(fsStatus);
@@ -99,24 +134,24 @@ public void testWorkingDirectory() throws Exception {
     Path workDir = path(getDefaultWorkingDirectory());
     assertEquals(workDir, fs.getWorkingDirectory());
 
-    fs.setWorkingDirectory(path("."));
+    fs.setWorkingDirectory(fs.makeQualified(new Path(".")));
     assertEquals(workDir, fs.getWorkingDirectory());
 
-    fs.setWorkingDirectory(path(".."));
+    fs.setWorkingDirectory(fs.makeQualified(new Path("..")));
     assertEquals(workDir.getParent(), fs.getWorkingDirectory());
 
-    Path relativeDir = path("hadoop");
+    Path relativeDir = fs.makeQualified(new Path("testWorkingDirectory"));
     fs.setWorkingDirectory(relativeDir);
     assertEquals(relativeDir, fs.getWorkingDirectory());
     
-    Path absoluteDir = path("/test/hadoop");
+    Path absoluteDir = path("/FileSystemContractBaseTest/testWorkingDirectory");
     fs.setWorkingDirectory(absoluteDir);
     assertEquals(absoluteDir, fs.getWorkingDirectory());
 
   }
   
   public void testMkdirs() throws Exception {
-    Path testDir = path("/test/hadoop");
+    Path testDir = path("testMkdirs");
     assertFalse(fs.exists(testDir));
     assertFalse(fs.isFile(testDir));
 
@@ -141,14 +176,15 @@ public void testMkdirs() throws Exception {
   }
   
   public void testMkdirsFailsForSubdirectoryOfExistingFile() throws Exception {
-    Path testDir = path("/test/hadoop");
+    Path testDir = path("testMkdirsFailsForSubdirectoryOfExistingFile");
     assertFalse(fs.exists(testDir));
     assertTrue(fs.mkdirs(testDir));
     assertTrue(fs.exists(testDir));
     
-    createFile(path("/test/hadoop/file"));
+    createFile(path("testMkdirsFailsForSubdirectoryOfExistingFile/file"));
     
-    Path testSubDir = path("/test/hadoop/file/subdir");
+    Path testSubDir =
+        path("testMkdirsFailsForSubdirectoryOfExistingFile/file/subdir");
     try {
       fs.mkdirs(testSubDir);
       fail("Should throw IOException.");
@@ -163,7 +199,8 @@ public void testMkdirsFailsForSubdirectoryOfExistingFile() throws Exception {
       // file missing execute permission.
     }
 
-    Path testDeepSubDir = path("/test/hadoop/file/deep/sub/dir");
+    Path testDeepSubDir = path(
+        "testMkdirsFailsForSubdirectoryOfExistingFile/file/deep/sub/dir");
     try {
       fs.mkdirs(testDeepSubDir);
       fail("Should throw IOException.");
@@ -189,7 +226,7 @@ public void testMkdirsWithUmask() throws Exception {
     String oldUmask = conf.get(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY);
     try {
       conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, TEST_UMASK);
-      final Path dir = new Path("/test/newDir");
+      final Path dir = new Path("newDir");
       assertTrue(fs.mkdirs(dir, new FsPermission((short)0777)));
       FileStatus status = fs.getFileStatus(dir);
       assertTrue(status.isDirectory());
@@ -202,7 +239,8 @@ public void testMkdirsWithUmask() throws Exception {
   public void testGetFileStatusThrowsExceptionForNonExistentFile() 
     throws Exception {
     try {
-      fs.getFileStatus(path("/test/hadoop/file"));
+      fs.getFileStatus(
+          path("testGetFileStatusThrowsExceptionForNonExistentFile/file"));
       fail("Should throw FileNotFoundException");
     } catch (FileNotFoundException e) {
       // expected
@@ -211,7 +249,8 @@ public void testGetFileStatusThrowsExceptionForNonExistentFile()
   
   public void testListStatusThrowsExceptionForNonExistentFile() throws Exception {
     try {
-      fs.listStatus(path("/test/hadoop/file"));
+      fs.listStatus(
+          path("testListStatusThrowsExceptionForNonExistentFile/file"));
       fail("Should throw FileNotFoundException");
     } catch (FileNotFoundException fnfe) {
       // expected
@@ -219,30 +258,32 @@ public void testListStatusThrowsExceptionForNonExistentFile() throws Exception {
   }
   
   public void testListStatus() throws Exception {
-    Path[] testDirs = { path("/test/hadoop/a"),
-                        path("/test/hadoop/b"),
-                        path("/test/hadoop/c/1"), };
+    final Path[] testDirs = {
+        path("testListStatus/a"),
+        path("testListStatus/b"),
+        path("testListStatus/c/1")
+    };
     assertFalse(fs.exists(testDirs[0]));
 
     for (Path path : testDirs) {
       assertTrue(fs.mkdirs(path));
     }
 
-    FileStatus[] paths = fs.listStatus(path("/test"));
+    FileStatus[] paths = fs.listStatus(path("."));
     assertEquals(1, paths.length);
-    assertEquals(path("/test/hadoop"), paths[0].getPath());
+    assertEquals(path("testListStatus"), paths[0].getPath());
 
-    paths = fs.listStatus(path("/test/hadoop"));
+    paths = fs.listStatus(path("testListStatus"));
     assertEquals(3, paths.length);
     ArrayList<Path> list = new ArrayList<Path>();
     for (FileStatus fileState : paths) {
       list.add(fileState.getPath());
     }
-    assertTrue(list.contains(path("/test/hadoop/a")));
-    assertTrue(list.contains(path("/test/hadoop/b")));
-    assertTrue(list.contains(path("/test/hadoop/c")));
+    assertTrue(list.contains(path("testListStatus/a")));
+    assertTrue(list.contains(path("testListStatus/b")));
+    assertTrue(list.contains(path("testListStatus/c")));
 
-    paths = fs.listStatus(path("/test/hadoop/a"));
+    paths = fs.listStatus(path("testListStatus/a"));
     assertEquals(0, paths.length);
   }
   
@@ -273,12 +314,12 @@ public void testWriteReadAndDeleteTwoBlocks() throws Exception {
    * @throws IOException on IO failures
    */
   protected void writeReadAndDelete(int len) throws IOException {
-    Path path = path("/test/hadoop/file");
+    Path path = path("writeReadAndDelete/file");
     writeAndRead(path, data, len, false, true);
   }
   
   public void testOverwrite() throws IOException {
-    Path path = path("/test/hadoop/file");
+    Path path = path("testOverwrite/file");
     
     fs.mkdirs(path.getParent());
 
@@ -304,7 +345,7 @@ public void testOverwrite() throws IOException {
   }
   
   public void testWriteInNonExistentDirectory() throws IOException {
-    Path path = path("/test/hadoop/file");
+    Path path = path("testWriteInNonExistentDirectory/file");
     assertFalse("Parent exists", fs.exists(path.getParent()));
     createFile(path);
     
@@ -314,15 +355,15 @@ public void testWriteInNonExistentDirectory() throws IOException {
   }
 
   public void testDeleteNonExistentFile() throws IOException {
-    Path path = path("/test/hadoop/file");    
+    Path path = path("testDeleteNonExistentFile/file");
     assertFalse("Path exists: " + path, fs.exists(path));
     assertFalse("No deletion", fs.delete(path, true));
   }
   
   public void testDeleteRecursively() throws IOException {
-    Path dir = path("/test/hadoop");
-    Path file = path("/test/hadoop/file");
-    Path subdir = path("/test/hadoop/subdir");
+    Path dir = path("testDeleteRecursively");
+    Path file = path("testDeleteRecursively/file");
+    Path subdir = path("testDeleteRecursively/subdir");
     
     createFile(file);
     assertTrue("Created subdir", fs.mkdirs(subdir));
@@ -348,7 +389,7 @@ public void testDeleteRecursively() throws IOException {
   }
   
   public void testDeleteEmptyDirectory() throws IOException {
-    Path dir = path("/test/hadoop");
+    Path dir = path("testDeleteEmptyDirectory");
     assertTrue(fs.mkdirs(dir));
     assertTrue("Dir exists", fs.exists(dir));
     assertTrue("Deleted", fs.delete(dir, false));
@@ -358,26 +399,26 @@ public void testDeleteEmptyDirectory() throws IOException {
   public void testRenameNonExistentPath() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/path");
-    Path dst = path("/test/new/newpath");
+    Path src = path("testRenameNonExistentPath/path");
+    Path dst = path("testRenameNonExistentPathNew/newpath");
     rename(src, dst, false, false, false);
   }
 
   public void testRenameFileMoveToNonExistentDirectory() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/file");
+    Path src = path("testRenameFileMoveToNonExistentDirectory/file");
     createFile(src);
-    Path dst = path("/test/new/newfile");
+    Path dst = path("testRenameFileMoveToNonExistentDirectoryNew/newfile");
     rename(src, dst, false, true, false);
   }
 
   public void testRenameFileMoveToExistingDirectory() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/file");
+    Path src = path("testRenameFileMoveToExistingDirectory/file");
     createFile(src);
-    Path dst = path("/test/new/newfile");
+    Path dst = path("testRenameFileMoveToExistingDirectoryNew/newfile");
     fs.mkdirs(dst.getParent());
     rename(src, dst, true, false, true);
   }
@@ -385,9 +426,9 @@ public void testRenameFileMoveToExistingDirectory() throws Exception {
   public void testRenameFileAsExistingFile() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/file");
+    Path src = path("testRenameFileAsExistingFile/file");
     createFile(src);
-    Path dst = path("/test/new/newfile");
+    Path dst = path("testRenameFileAsExistingFileNew/newfile");
     createFile(dst);
     rename(src, dst, false, true, true);
   }
@@ -395,84 +436,84 @@ public void testRenameFileAsExistingFile() throws Exception {
   public void testRenameFileAsExistingDirectory() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/file");
+    Path src = path("testRenameFileAsExistingDirectory/file");
     createFile(src);
-    Path dst = path("/test/new/newdir");
+    Path dst = path("testRenameFileAsExistingDirectoryNew/newdir");
     fs.mkdirs(dst);
     rename(src, dst, true, false, true);
     assertTrue("Destination changed",
-        fs.exists(path("/test/new/newdir/file")));
+        fs.exists(path("testRenameFileAsExistingDirectoryNew/newdir/file")));
   }
   
   public void testRenameDirectoryMoveToNonExistentDirectory() 
     throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/dir");
+    Path src = path("testRenameDirectoryMoveToNonExistentDirectory/dir");
     fs.mkdirs(src);
-    Path dst = path("/test/new/newdir");
+    Path dst = path("testRenameDirectoryMoveToNonExistentDirectoryNew/newdir");
     rename(src, dst, false, true, false);
   }
   
   public void testRenameDirectoryMoveToExistingDirectory() throws Exception {
     if (!renameSupported()) return;
-    
-    Path src = path("/test/hadoop/dir");
+
+    Path src = path("testRenameDirectoryMoveToExistingDirectory/dir");
     fs.mkdirs(src);
-    createFile(path("/test/hadoop/dir/file1"));
-    createFile(path("/test/hadoop/dir/subdir/file2"));
-    
-    Path dst = path("/test/new/newdir");
+    createFile(path(src + "/file1"));
+    createFile(path(src + "/subdir/file2"));
+
+    Path dst = path("testRenameDirectoryMoveToExistingDirectoryNew/newdir");
     fs.mkdirs(dst.getParent());
     rename(src, dst, true, false, true);
     
     assertFalse("Nested file1 exists",
-        fs.exists(path("/test/hadoop/dir/file1")));
+        fs.exists(path(src + "/file1")));
     assertFalse("Nested file2 exists",
-        fs.exists(path("/test/hadoop/dir/subdir/file2")));
+        fs.exists(path(src + "/subdir/file2")));
     assertTrue("Renamed nested file1 exists",
-        fs.exists(path("/test/new/newdir/file1")));
+        fs.exists(path(dst + "/file1")));
     assertTrue("Renamed nested exists",
-        fs.exists(path("/test/new/newdir/subdir/file2")));
+        fs.exists(path(dst + "/subdir/file2")));
   }
   
   public void testRenameDirectoryAsExistingFile() throws Exception {
     if (!renameSupported()) return;
     
-    Path src = path("/test/hadoop/dir");
+    Path src = path("testRenameDirectoryAsExistingFile/dir");
     fs.mkdirs(src);
-    Path dst = path("/test/new/newfile");
+    Path dst = path("testRenameDirectoryAsExistingFileNew/newfile");
     createFile(dst);
     rename(src, dst, false, true, true);
   }
   
   public void testRenameDirectoryAsExistingDirectory() throws Exception {
     if (!renameSupported()) return;
-    
-    Path src = path("/test/hadoop/dir");
+
+    Path src = path("testRenameDirectoryAsExistingDirectory/dir");
     fs.mkdirs(src);
-    createFile(path("/test/hadoop/dir/file1"));
-    createFile(path("/test/hadoop/dir/subdir/file2"));
+    createFile(path(src + "/file1"));
+    createFile(path(src + "/subdir/file2"));
     
-    Path dst = path("/test/new/newdir");
+    Path dst = path("testRenameDirectoryAsExistingDirectoryNew/newdir");
     fs.mkdirs(dst);
     rename(src, dst, true, false, true);
     assertTrue("Destination changed",
-        fs.exists(path("/test/new/newdir/dir")));    
+        fs.exists(path(dst + "/dir")));
     assertFalse("Nested file1 exists",
-        fs.exists(path("/test/hadoop/dir/file1")));
+        fs.exists(path(src + "/file1")));
     assertFalse("Nested file2 exists",
-        fs.exists(path("/test/hadoop/dir/subdir/file2")));
+        fs.exists(path(src + "r/subdir/file2")));
     assertTrue("Renamed nested file1 exists",
-        fs.exists(path("/test/new/newdir/dir/file1")));
+        fs.exists(path(dst + "/dir/file1")));
     assertTrue("Renamed nested exists",
-        fs.exists(path("/test/new/newdir/dir/subdir/file2")));
+        fs.exists(path(dst + "/dir/subdir/file2")));
   }
 
   public void testInputStreamClosedTwice() throws IOException {
     //HADOOP-4760 according to Closeable#close() closing already-closed 
     //streams should have no effect. 
-    Path src = path("/test/hadoop/file");
+    Path src = path("testInputStreamClosedTwice/file");
     createFile(src);
     FSDataInputStream in = fs.open(src);
     in.close();
@@ -482,17 +523,13 @@ public void testInputStreamClosedTwice() throws IOException {
   public void testOutputStreamClosedTwice() throws IOException {
     //HADOOP-4760 according to Closeable#close() closing already-closed 
     //streams should have no effect. 
-    Path src = path("/test/hadoop/file");
+    Path src = path("testOutputStreamClosedTwice/file");
     FSDataOutputStream out = fs.create(src);
     out.writeChar('H'); //write some data
     out.close();
     out.close();
   }
-  
-  protected Path path(String pathString) {
-    return new Path(pathString).makeQualified(fs);
-  }
-  
+
   protected void createFile(Path path) throws IOException {
     FSDataOutputStream out = fs.create(path);
     out.write(data, 0, data.length);
@@ -520,7 +557,7 @@ public void testOverWriteAndRead() throws Exception {
 
     byte[] filedata1 = dataset(blockSize * 2, 'A', 26);
     byte[] filedata2 = dataset(blockSize * 2, 'a', 26);
-    Path path = path("/test/hadoop/file-overwrite");
+    Path path = path("testOverWriteAndRead/file-overwrite");
     writeAndRead(path, filedata1, blockSize, true, false);
     writeAndRead(path, filedata2, blockSize, true, false);
     writeAndRead(path, filedata1, blockSize * 2, true, false);
diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java
index 1f46853..6a0f878 100644
--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java
+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AFileSystemContract.java
@@ -59,35 +59,13 @@ public void setUp() throws Exception {
 
     fs = S3ATestUtils.createTestFileSystem(conf);
     basePath = fs.makeQualified(
-        S3ATestUtils.createTestPath(new Path("/s3afilesystemcontract")));
+        S3ATestUtils.createTestPath(new Path("s3afilesystemcontract")));
     super.setUp();
   }
 
-  /**
-   * This path explicitly places all absolute paths under the per-test suite
-   * path directory; this allows the test to run in parallel.
-   * @param pathString path string as input
-   * @return a qualified path string.
-   */
-  protected Path path(String pathString) {
-    if (pathString.startsWith("/")) {
-      return fs.makeQualified(new Path(basePath, pathString));
-    } else {
-      return super.path(pathString);
-    }
-  }
-
   @Override
-  protected void tearDown() throws Exception {
-    if (fs != null) {
-      try {
-        LOG.info("Deleting {}", basePath);
-        fs.delete(basePath, true);
-      } catch (IOException e) {
-        LOG.info("Failed to delete {}", basePath);
-      }
-    }
-    super.tearDown();
+  public Path getTestBaseDir() {
+    return basePath;
   }
 
   @Override
@@ -101,22 +79,22 @@ public void testRenameDirectoryAsExistingDirectory() throws Exception {
       return;
     }
 
-    Path src = path("/test/hadoop/dir");
+    Path src = path("testRenameDirectoryAsExisting/dir");
     fs.mkdirs(src);
-    createFile(path("/test/hadoop/dir/file1"));
-    createFile(path("/test/hadoop/dir/subdir/file2"));
+    createFile(path(src + "/file1"));
+    createFile(path(src + "/subdir/file2"));
 
-    Path dst = path("/test/new/newdir");
+    Path dst = path("testRenameDirectoryAsExistingNew/newdir");
     fs.mkdirs(dst);
     rename(src, dst, true, false, true);
     assertFalse("Nested file1 exists",
-                fs.exists(path("/test/hadoop/dir/file1")));
+        fs.exists(path(src + "/file1")));
     assertFalse("Nested file2 exists",
-                fs.exists(path("/test/hadoop/dir/subdir/file2")));
+        fs.exists(path(src + "/subdir/file2")));
     assertTrue("Renamed nested file1 exists",
-               fs.exists(path("/test/new/newdir/file1")));
+        fs.exists(path(dst + "/file1")));
     assertTrue("Renamed nested exists",
-               fs.exists(path("/test/new/newdir/subdir/file2")));
+        fs.exists(path(dst + "/subdir/file2")));
   }
 
 //  @Override
-- 
1.7.9.5

