From f561c226682d2aef39dd6e99b5296428c6e4f46c Mon Sep 17 00:00:00 2001
From: Aaron Fabbri <fabbri@cloudera.com>
Date: Wed, 25 May 2016 20:57:49 -0700
Subject: [PATCH 1594/2748] CDH-24695 CLOUDERA-BUILD Copying a local file to
 s3 via hdfs cli is slow

Change multipart upload parameters so the feature actually gets used.

- Multipart threshold 2GB -> 16MB
- Multipart size 100MB -> 8MB

New values based on testing and comparing to what AWS CLI does today.

Change-Id: I18247b784c3ca593c977453c83f7c0a07d4bc143
---
 .../src/main/resources/core-default.xml            |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
index 1f58e57..8a4fc0b 100644
--- a/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
+++ b/hadoop-common-project/hadoop-common/src/main/resources/core-default.xml
@@ -857,13 +857,13 @@ for ldap providers in the same way as above does.
 
 <property>
   <name>fs.s3a.multipart.size</name>
-  <value>104857600</value>
+  <value>8388608</value>
   <description>How big (in bytes) to split upload or copy operations up into.</description>
 </property>
 
 <property>
   <name>fs.s3a.multipart.threshold</name>
-  <value>2147483647</value>
+  <value>16777216</value>
   <description>Threshold before uploads or copies use parallel multipart operations.</description>
 </property>
 
-- 
1.7.9.5

