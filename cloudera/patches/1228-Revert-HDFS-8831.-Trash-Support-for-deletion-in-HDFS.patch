From eb076ae12d74ecef66cb1499bd00293390cfc697 Mon Sep 17 00:00:00 2001
From: Zhe Zhang <zhz@apache.org>
Date: Fri, 12 Feb 2016 10:36:57 -0800
Subject: [PATCH 1228/2748] Revert "HDFS-8831. Trash Support for deletion in
 HDFS encryption zone. Contributed by Xiaoyu Yao."

This reverts commit 94fe537022f28444fb900766e1937233840929a7.

Change-Id: I77c8f2b8972e831bcc557f1df88c9df9619fa2f1
---
 .../main/java/org/apache/hadoop/fs/FileSystem.java |   52 +-----
 .../org/apache/hadoop/fs/FilterFileSystem.java     |   12 --
 .../main/java/org/apache/hadoop/fs/FsShell.java    |   12 +-
 .../src/main/java/org/apache/hadoop/fs/Trash.java  |   15 +-
 .../java/org/apache/hadoop/fs/TrashPolicy.java     |   56 +-----
 .../org/apache/hadoop/fs/TrashPolicyDefault.java   |  193 ++++++++------------
 .../org/apache/hadoop/fs/TestHarFileSystem.java    |    5 -
 .../test/java/org/apache/hadoop/fs/TestTrash.java  |    9 -
 .../apache/hadoop/hdfs/DistributedFileSystem.java  |   61 -------
 .../apache/hadoop/hdfs/TestEncryptionZones.java    |   47 -----
 10 files changed, 94 insertions(+), 368 deletions(-)

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
index 527fa8b..c9e8f47 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java
@@ -27,7 +27,6 @@
 import java.security.PrivilegedExceptionAction;
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collection;
 import java.util.EnumSet;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -104,8 +103,6 @@
    */
   public static final int SHUTDOWN_HOOK_PRIORITY = 10;
 
-  public static final String TRASH_PREFIX = ".Trash";
-
   /** FileSystem cache */
   static final Cache CACHE = new Cache();
 
@@ -2592,53 +2589,6 @@ public void removeXAttr(Path path, String name) throws IOException {
         + " doesn't support removeXAttr");
   }
 
-  /**
-   * Get the root directory of Trash for current user when the path specified
-   * is deleted.
-   *
-   * @param path the trash root of the path to be determined.
-   * @return the default implementation returns "/user/$USER/.Trash".
-   * @throws IOException
-   */
-  public Path getTrashRoot(Path path) throws IOException {
-    return this.makeQualified(new Path(getHomeDirectory().toUri().getPath(),
-        TRASH_PREFIX));
-  }
-
-  /**
-   * Get all the trash roots for current user or all users.
-   *
-   * @param allUsers return trash roots for all users if true.
-   * @return all the trash root directories.
-   *         Default FileSystem returns .Trash under users' home directories if
-   *         /user/$USER/.Trash exists.
-   * @throws IOException
-   */
-  public Collection<FileStatus> getTrashRoots(boolean allUsers)
-      throws IOException {
-    Path userHome = new Path(getHomeDirectory().toUri().getPath());
-    List<FileStatus> ret = new ArrayList<FileStatus>();
-    if (!allUsers) {
-      Path userTrash = new Path(userHome, TRASH_PREFIX);
-      if (exists(userTrash)) {
-        ret.add(getFileStatus(userTrash));
-      }
-    } else {
-      Path homeParent = userHome.getParent();
-      if (exists(homeParent)) {
-        FileStatus[] candidates = listStatus(homeParent);
-        for (FileStatus candidate : candidates) {
-          Path userTrash = new Path(candidate.getPath(), TRASH_PREFIX);
-          if (exists(userTrash)) {
-            candidate.setPath(userTrash);
-            ret.add(candidate);
-          }
-        }
-      }
-    }
-    return ret;
-  }
-
   // making it volatile to be able to do a double checked locking
   private volatile static boolean FILE_SYSTEMS_LOADED = false;
 
@@ -3164,7 +3114,7 @@ public void incrementWriteOps(int count) {
      * For each StatisticsData object, we will call accept on the visitor.
      * Finally, at the end, we will call aggregate to get the final total. 
      *
-     * @param         visitor to use.
+     * @param         The visitor to use.
      * @return        The total.
      */
     private synchronized <T> T visitAll(StatisticsAggregator<T> visitor) {
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
index ca9e4da..e2a42e5 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FilterFileSystem.java
@@ -21,7 +21,6 @@
 import java.io.*;
 import java.net.URI;
 import java.net.URISyntaxException;
-import java.util.Collection;
 import java.util.EnumSet;
 import java.util.List;
 import java.util.Map;
@@ -615,15 +614,4 @@ public void setXAttr(Path path, String name, byte[] value,
   public void removeXAttr(Path path, String name) throws IOException {
     fs.removeXAttr(path, name);
   }
-
-  @Override
-  public Path getTrashRoot(Path path) throws IOException {
-    return fs.getTrashRoot(path);
-  }
-
-  @Override
-  public Collection<FileStatus> getTrashRoots(boolean allUsers)
-      throws IOException {
-    return fs.getTrashRoots(allUsers);
-  }
 }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsShell.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsShell.java
index b23a7e6..9a5b651 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsShell.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FsShell.java
@@ -121,21 +121,11 @@ public Path getCurrentTrashDir() throws IOException {
     return getTrash().getCurrentTrashDir();
   }
 
-  /**
-   * Returns the current trash location for the path specified
-   * @param path to be deleted
-   * @return path to the trash
-   * @throws IOException
-   */
-  public Path getCurrentTrashDir(Path path) throws IOException {
-    return getTrash().getCurrentTrashDir(path);
-  }
-
   // NOTE: Usage/Help are inner classes to allow access to outer methods
   // that access commandFactory
   
   /**
-   *  Display help for commands with their short usage and long description.
+   *  Display help for commands with their short usage and long description
    */
    protected class Usage extends FsCommand {
     public static final String NAME = "usage";
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Trash.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Trash.java
index b771812..aae5cf7 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Trash.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Trash.java
@@ -54,7 +54,7 @@ public Trash(Configuration conf) throws IOException {
    */
   public Trash(FileSystem fs, Configuration conf) throws IOException {
     super(conf);
-    trashPolicy = TrashPolicy.getInstance(conf, fs);
+    trashPolicy = TrashPolicy.getInstance(conf, fs, fs.getHomeDirectory());
   }
 
   /**
@@ -92,7 +92,12 @@ public static boolean moveToAppropriateTrash(FileSystem fs, Path p,
       throw new IOException("Failed to get server trash configuration", e);
     }
     Trash trash = new Trash(fullyResolvedFs, conf);
-    return trash.moveToTrash(fullyResolvedPath);
+    boolean success = trash.moveToTrash(fullyResolvedPath);
+    if (success) {
+      System.out.println("Moved: '" + p + "' to trash at: " +
+          trash.getCurrentTrashDir() );
+    }
+    return success;
   }
   
   /**
@@ -120,7 +125,7 @@ public void expunge() throws IOException {
   }
 
   /** get the current working directory */
-  Path getCurrentTrashDir() throws IOException {
+  Path getCurrentTrashDir() {
     return trashPolicy.getCurrentTrashDir();
   }
 
@@ -135,8 +140,4 @@ TrashPolicy getTrashPolicy() {
   public Runnable getEmptier() throws IOException {
     return trashPolicy.getEmptier();
   }
-
-  public Path getCurrentTrashDir(Path path) throws IOException {
-    return trashPolicy.getCurrentTrashDir(path);
-  }
 }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
index 1d901c1..eab83b3 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicy.java
@@ -38,7 +38,7 @@
 
   /**
    * Used to setup the trash policy. Must be implemented by all TrashPolicy
-   * implementations.
+   * implementations
    * @param conf the configuration to be used
    * @param fs the filesystem to be used
    * @param home the home directory
@@ -46,19 +46,7 @@
   public abstract void initialize(Configuration conf, FileSystem fs, Path home);
 
   /**
-   * Used to setup the trash policy. Must be implemented by all TrashPolicy
-   * implementations. Different from initialize(conf, fs, home), this one does
-   * not assume trash always under /user/$USER due to HDFS encryption zone.
-   * @param conf the configuration to be used
-   * @param fs the filesystem to be used
-   * @throws IOException
-   */
-  public void initialize(Configuration conf, FileSystem fs) throws IOException{
-    throw new UnsupportedOperationException();
-  }
-
-  /**
-   * Returns whether the Trash Policy is enabled for this filesystem.
+   * Returns whether the Trash Policy is enabled for this filesystem
    */
   public abstract boolean isEnabled();
 
@@ -80,27 +68,8 @@ public void initialize(Configuration conf, FileSystem fs) throws IOException{
 
   /**
    * Get the current working directory of the Trash Policy
-   * This API does not work with files deleted from encryption zone when HDFS
-   * data encryption at rest feature is enabled as rename file between
-   * encryption zones or encryption zone and non-encryption zone is not allowed.
-   *
-   * The caller is recommend to use the new API
-   * TrashPolicy#getCurrentTrashDir(Path path).
-   * It returns the trash location correctly for the path specified no matter
-   * the path is in encryption zone or not.
-   */
-  public abstract Path getCurrentTrashDir() throws IOException;
-
-  /**
-   * Get the current trash directory for path specified based on the Trash
-   * Policy
-   * @param path path to be deleted
-   * @return current trash directory for the path to be deleted
-   * @throws IOException
    */
-  public Path getCurrentTrashDir(Path path) throws IOException {
-    throw new UnsupportedOperationException();
-  }
+  public abstract Path getCurrentTrashDir();
 
   /** 
    * Return a {@link Runnable} that periodically empties the trash of all
@@ -109,7 +78,7 @@ public Path getCurrentTrashDir(Path path) throws IOException {
   public abstract Runnable getEmptier() throws IOException;
 
   /**
-   * Get an instance of the configured TrashPolicy based on the value
+   * Get an instance of the configured TrashPolicy based on the value 
    * of the configuration parameter fs.trash.classname.
    *
    * @param conf the configuration to be used
@@ -124,21 +93,4 @@ public static TrashPolicy getInstance(Configuration conf, FileSystem fs, Path ho
     trash.initialize(conf, fs, home); // initialize TrashPolicy
     return trash;
   }
-
-  /**
-   * Get an instance of the configured TrashPolicy based on the value
-   * of the configuration parameter fs.trash.classname.
-   *
-   * @param conf the configuration to be used
-   * @param fs the file system to be used
-   * @return an instance of TrashPolicy
-   */
-  public static TrashPolicy getInstance(Configuration conf, FileSystem fs)
-      throws IOException {
-    Class<? extends TrashPolicy> trashClass = conf.getClass(
-        "fs.trash.classname", TrashPolicyDefault.class, TrashPolicy.class);
-    TrashPolicy trash = ReflectionUtils.newInstance(trashClass, conf);
-    trash.initialize(conf, fs); // initialize TrashPolicy
-    return trash;
-  }
 }
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
index efc0072..efe6efd 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
@@ -27,7 +27,6 @@
 import java.text.DateFormat;
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
-import java.util.Collection;
 import java.util.Date;
 
 import org.apache.commons.logging.Log;
@@ -67,18 +66,23 @@
       new SimpleDateFormat("yyMMddHHmm");
   private static final int MSECS_PER_MINUTE = 60*1000;
 
+  private Path current;
+  private Path homesParent;
   private long emptierInterval;
 
   public TrashPolicyDefault() { }
 
-  private TrashPolicyDefault(FileSystem fs, Configuration conf)
+  private TrashPolicyDefault(FileSystem fs, Path home, Configuration conf)
       throws IOException {
-    initialize(conf, fs);
+    initialize(conf, fs, home);
   }
 
   @Override
   public void initialize(Configuration conf, FileSystem fs, Path home) {
     this.fs = fs;
+    this.trash = new Path(home, TRASH);
+    this.homesParent = home.getParent();
+    this.current = new Path(trash, CURRENT);
     this.deletionInterval = (long)(conf.getFloat(
         FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)
         * MSECS_PER_MINUTE);
@@ -90,17 +94,6 @@ public void initialize(Configuration conf, FileSystem fs, Path home) {
              (this.emptierInterval / MSECS_PER_MINUTE) + " minutes.");
    }
 
-  @Override
-  public void initialize(Configuration conf, FileSystem fs) {
-    this.fs = fs;
-    this.deletionInterval = (long)(conf.getFloat(
-        FS_TRASH_INTERVAL_KEY, FS_TRASH_INTERVAL_DEFAULT)
-        * MSECS_PER_MINUTE);
-    this.emptierInterval = (long)(conf.getFloat(
-        FS_TRASH_CHECKPOINT_INTERVAL_KEY, FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT)
-        * MSECS_PER_MINUTE);
-  }
-
   private Path makeTrashRelativePath(Path basePath, Path rmFilePath) {
     return Path.mergePaths(basePath, rmFilePath);
   }
@@ -123,19 +116,17 @@ public boolean moveToTrash(Path path) throws IOException {
 
     String qpath = fs.makeQualified(path).toString();
 
-    Path trashRoot = fs.getTrashRoot(path);
-    Path trashCurrent = new Path(trashRoot, CURRENT);
-    if (qpath.startsWith(trashRoot.toString())) {
+    if (qpath.startsWith(trash.toString())) {
       return false;                               // already in trash
     }
 
-    if (trashRoot.getParent().toString().startsWith(qpath)) {
+    if (trash.getParent().toString().startsWith(qpath)) {
       throw new IOException("Cannot move \"" + path +
                             "\" to the trash, as it contains the trash");
     }
 
-    Path trashPath = makeTrashRelativePath(trashCurrent, path);
-    Path baseTrashPath = makeTrashRelativePath(trashCurrent, path.getParent());
+    Path trashPath = makeTrashRelativePath(current, path);
+    Path baseTrashPath = makeTrashRelativePath(current, path.getParent());
     
     IOException cause = null;
 
@@ -160,16 +151,14 @@ public boolean moveToTrash(Path path) throws IOException {
           trashPath = new Path(orig + Time.now());
         }
         
-        if (fs.rename(path, trashPath)) {           // move to current trash
-          LOG.info("Moved: '" + path + "' to trash at: " + trashPath);
+        if (fs.rename(path, trashPath))           // move to current trash
           return true;
-        }
       } catch (IOException e) {
         cause = e;
       }
     }
     throw (IOException)
-      new IOException("Failed to move to trash: " + path).initCause(cause);
+      new IOException("Failed to move to trash: "+path).initCause(cause);
   }
 
   @SuppressWarnings("deprecation")
@@ -180,32 +169,72 @@ public void createCheckpoint() throws IOException {
 
   @SuppressWarnings("deprecation")
   public void createCheckpoint(Date date) throws IOException {
-    Collection<FileStatus> trashRoots = fs.getTrashRoots(false);
-    for (FileStatus trashRoot: trashRoots) {
-      LOG.info("TrashPolicyDefault#createCheckpoint for trashRoot: " +
-          trashRoot.getPath());
-      createCheckpoint(trashRoot.getPath(), date);
+
+    if (!fs.exists(current))                     // no trash, no checkpoint
+      return;
+
+    Path checkpointBase;
+    synchronized (CHECKPOINT) {
+      checkpointBase = new Path(trash, CHECKPOINT.format(date));
+
     }
+    Path checkpoint = checkpointBase;
+
+    int attempt = 0;
+    while (true) {
+      try {
+        fs.rename(current, checkpoint, Rename.NONE);
+        break;
+      } catch (FileAlreadyExistsException e) {
+        if (++attempt > 1000) {
+          throw new IOException("Failed to checkpoint trash: "+checkpoint);
+        }
+        checkpoint = checkpointBase.suffix("-" + attempt);
+      }
+    }
+
+    LOG.info("Created trash checkpoint: "+checkpoint.toUri().getPath());
   }
 
   @Override
   public void deleteCheckpoint() throws IOException {
-    Collection<FileStatus> trashRoots = fs.getTrashRoots(false);
-    for (FileStatus trashRoot : trashRoots) {
-      LOG.info("TrashPolicyDefault#deleteCheckpoint for trashRoot: " +
-          trashRoot.getPath());
-      deleteCheckpoint(trashRoot.getPath());
+    FileStatus[] dirs = null;
+    
+    try {
+      dirs = fs.listStatus(trash);            // scan trash sub-directories
+    } catch (FileNotFoundException fnfe) {
+      return;
     }
-  }
 
-  @Override
-  public Path getCurrentTrashDir() throws IOException {
-    return new Path(fs.getTrashRoot(null), CURRENT);
+    long now = Time.now();
+    for (int i = 0; i < dirs.length; i++) {
+      Path path = dirs[i].getPath();
+      String dir = path.toUri().getPath();
+      String name = path.getName();
+      if (name.equals(CURRENT.getName()))         // skip current
+        continue;
+
+      long time;
+      try {
+        time = getTimeFromCheckpoint(name);
+      } catch (ParseException e) {
+        LOG.warn("Unexpected item in trash: "+dir+". Ignoring.");
+        continue;
+      }
+
+      if ((now - deletionInterval) > time) {
+        if (fs.delete(path, true)) {
+          LOG.info("Deleted trash checkpoint: "+dir);
+        } else {
+          LOG.warn("Couldn't delete checkpoint: "+dir+" Ignoring.");
+        }
+      }
+    }
   }
 
   @Override
-  public Path getCurrentTrashDir(Path path) throws IOException {
-    return new Path(fs.getTrashRoot(path), CURRENT);
+  public Path getCurrentTrashDir() {
+    return current;
   }
 
   @Override
@@ -248,24 +277,25 @@ public void run() {
         try {
           now = Time.now();
           if (now >= end) {
-            Collection<FileStatus> trashRoots;
+
+            FileStatus[] homes = null;
             try {
-              trashRoots = fs.getTrashRoots(true);      // list all home dirs
+              homes = fs.listStatus(homesParent);         // list all home dirs
             } catch (IOException e) {
-              LOG.warn("Trash can't list all trash roots: "+e+" Sleeping.");
+              LOG.warn("Trash can't list homes: "+e+" Sleeping.");
               continue;
             }
 
-            for (FileStatus trashRoot : trashRoots) {   // dump each trash
-              if (!trashRoot.isDirectory())
+            for (FileStatus home : homes) {         // dump each trash
+              if (!home.isDirectory())
                 continue;
               try {
-                TrashPolicyDefault trash = new TrashPolicyDefault(fs, conf);
-                trash.deleteCheckpoint(trashRoot.getPath());
-                trash.createCheckpoint(trashRoot.getPath(), new Date(now));
+                TrashPolicyDefault trash = new TrashPolicyDefault(
+                    fs, home.getPath(), conf);
+                trash.deleteCheckpoint();
+                trash.createCheckpoint(new Date(now));
               } catch (IOException e) {
-                LOG.warn("Trash caught: "+e+". Skipping " +
-                    trashRoot.getPath() + ".");
+                LOG.warn("Trash caught: "+e+". Skipping "+home.getPath()+".");
               } 
             }
           }
@@ -288,69 +318,6 @@ private long floor(long time, long interval) {
     }
   }
 
-  private void createCheckpoint(Path trashRoot, Date date) throws IOException {
-    if (!fs.exists(new Path(trashRoot, CURRENT))) {
-      return;
-    }
-    Path checkpointBase;
-    synchronized (CHECKPOINT) {
-      checkpointBase = new Path(trashRoot, CHECKPOINT.format(date));
-    }
-    Path checkpoint = checkpointBase;
-    Path current = new Path(trashRoot, CURRENT);
-
-    int attempt = 0;
-    while (true) {
-      try {
-        fs.rename(current, checkpoint, Rename.NONE);
-        LOG.info("Created trash checkpoint: " + checkpoint.toUri().getPath());
-        break;
-      } catch (FileAlreadyExistsException e) {
-        if (++attempt > 1000) {
-          throw new IOException("Failed to checkpoint trash: " + checkpoint);
-        }
-        checkpoint = checkpointBase.suffix("-" + attempt);
-      }
-    }
-  }
-
-  private void deleteCheckpoint(Path trashRoot) throws IOException {
-    LOG.info("TrashPolicyDefault#deleteCheckpoint for trashRoot: " + trashRoot);
-
-    FileStatus[] dirs = null;
-    try {
-      dirs = fs.listStatus(trashRoot); // scan trash sub-directories
-    } catch (FileNotFoundException fnfe) {
-      return;
-    }
-
-    long now = Time.now();
-    for (int i = 0; i < dirs.length; i++) {
-      Path path = dirs[i].getPath();
-      String dir = path.toUri().getPath();
-      String name = path.getName();
-      if (name.equals(CURRENT.getName())) {         // skip current
-        continue;
-      }
-
-      long time;
-      try {
-        time = getTimeFromCheckpoint(name);
-      } catch (ParseException e) {
-        LOG.warn("Unexpected item in trash: "+dir+". Ignoring.");
-        continue;
-      }
-
-      if ((now - deletionInterval) > time) {
-        if (fs.delete(path, true)) {
-          LOG.info("Deleted trash checkpoint: "+dir);
-        } else {
-          LOG.warn("Couldn't delete checkpoint: " + dir + " Ignoring.");
-        }
-      }
-    }
-  }
-
   private long getTimeFromCheckpoint(String name) throws ParseException {
     long time;
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestHarFileSystem.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestHarFileSystem.java
index 3bc016c..374bb2e 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestHarFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestHarFileSystem.java
@@ -34,7 +34,6 @@
 import java.io.IOException;
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
-import java.util.Collection;
 import java.util.EnumSet;
 import java.util.Iterator;
 import java.util.List;
@@ -206,10 +205,6 @@ public void setXAttr(Path path, String name, byte[] value,
     public AclStatus getAclStatus(Path path) throws IOException;
 
     public void access(Path path, FsAction mode) throws IOException;
-
-    public Path getTrashRoot(Path path) throws IOException;
-
-    public Collection<FileStatus> getTrashRoots(boolean allUsers) throws IOException;
   }
 
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
index 88194fd..9a91733 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
@@ -696,10 +696,6 @@ public void initialize(Configuration conf, FileSystem fs, Path home) {
     }
 
     @Override
-    public void initialize(Configuration conf, FileSystem fs) {
-    }
-
-    @Override
     public boolean isEnabled() {
       return false;
     }
@@ -723,11 +719,6 @@ public Path getCurrentTrashDir() {
     }
 
     @Override
-    public Path getCurrentTrashDir(Path path) throws IOException {
-      return null;
-    }
-
-    @Override
     public Runnable getEmptier() throws IOException {
       return null;
     }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
index 4efdb27..7638bb9 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DistributedFileSystem.java
@@ -23,7 +23,6 @@
 import java.net.InetSocketAddress;
 import java.net.URI;
 import java.util.ArrayList;
-import java.util.Collection;
 import java.util.EnumSet;
 import java.util.List;
 import java.util.Map;
@@ -2162,64 +2161,4 @@ public DFSInotifyEventInputStream getInotifyEventStream(long lastReadTxid)
       throws IOException {
     return dfs.getInotifyEventStream(lastReadTxid);
   }
-  /**
-   * Get the root directory of Trash for a path in HDFS.
-   * 1. File in encryption zone returns /ez1/.Trash/username
-   * 2. File not in encryption zone returns /users/username/.Trash
-   * Caller appends either Current or checkpoint timestamp for trash destination
-   * @param path the trash root of the path to be determined.
-   * @return trash root
-   * @throws IOException
-   */
-  @Override
-  public Path getTrashRoot(Path path) throws IOException {
-    if ((path == null) || !dfs.isHDFSEncryptionEnabled()) {
-      return super.getTrashRoot(path);
-    }
-
-    String absSrc = path.toUri().getPath();
-    EncryptionZone ez = dfs.getEZForPath(absSrc);
-    if ((ez != null) && !ez.getPath().equals(absSrc)) {
-      return this.makeQualified(
-          new Path(ez.getPath() + "/" + FileSystem.TRASH_PREFIX +
-              dfs.ugi.getShortUserName()));
-    } else {
-      return super.getTrashRoot(path);
-    }
-  }
-
-  /**
-   * Get all the trash roots of HDFS for current user or for all the users.
-   * 1. File deleted from non-encryption zone /user/username/.Trash
-   * 2. File deleted from encryption zones
-   *    e.g., ez1 rooted at /ez1 has its trash root at /ez1/.Trash/$USER
-   * @allUsers return trashRoots of all users if true, used by emptier
-   * @return trash roots of HDFS
-   * @throws IOException
-   */
-  @Override
-  public Collection<FileStatus> getTrashRoots(boolean allUsers) throws IOException {
-    List<FileStatus> ret = new ArrayList<FileStatus>();
-    // Get normal trash roots
-    ret.addAll(super.getTrashRoots(allUsers));
-
-    // Get EZ Trash roots
-    final RemoteIterator<EncryptionZone> it = dfs.listEncryptionZones();
-    while (it.hasNext()) {
-      Path ezTrashRoot = new Path(it.next().getPath(), FileSystem.TRASH_PREFIX);
-      if (allUsers) {
-        for (FileStatus candidate : listStatus(ezTrashRoot)) {
-          if (exists(candidate.getPath())) {
-            ret.add(candidate);
-          }
-        }
-      } else {
-        Path userTrash = new Path(ezTrashRoot, System.getProperty("user.name"));
-        if (exists(userTrash)) {
-          ret.add(getFileStatus(userTrash));
-        }
-      }
-    }
-    return ret;
-  }
 }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java
index 35cedde..2687a0f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java
@@ -57,7 +57,6 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.FileSystemTestHelper;
 import org.apache.hadoop.fs.FileSystemTestWrapper;
-import org.apache.hadoop.fs.FsShell;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.RemoteIterator;
 import org.apache.hadoop.fs.permission.FsPermission;
@@ -99,7 +98,6 @@
 import static org.mockito.Mockito.withSettings;
 import static org.mockito.Mockito.any;
 import static org.mockito.Mockito.anyString;
-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_TRASH_INTERVAL_KEY;
 import static org.apache.hadoop.hdfs.DFSTestUtil.verifyFilesEqual;
 import static org.apache.hadoop.test.GenericTestUtils.assertExceptionContains;
 import static org.junit.Assert.assertEquals;
@@ -1350,49 +1348,4 @@ public void testEncryptionZonesOnRootPath() throws Exception {
         true, fs.getFileStatus(zoneFile).isEncrypted());
     DFSTestUtil.verifyFilesNotEqual(fs, zoneFile, rawFile, len);
   }
-
-  @Test(timeout = 120000)
-  public void testEncryptionZoneWithTrash() throws Exception {
-    // Create the encryption zone1
-    final HdfsAdmin dfsAdmin =
-        new HdfsAdmin(FileSystem.getDefaultUri(conf), conf);
-    final Path zone1 = new Path("/zone1");
-    fs.mkdirs(zone1);
-    dfsAdmin.createEncryptionZone(zone1, TEST_KEY);
-
-    // Create the encrypted file in zone1
-    final Path encFile1 = new Path(zone1, "encFile1");
-    final int len = 8192;
-    DFSTestUtil.createFile(fs, encFile1, len, (short) 1, 0xFEED);
-
-    Configuration clientConf = new Configuration(conf);
-    clientConf.setLong(FS_TRASH_INTERVAL_KEY, 1);
-    FsShell shell = new FsShell(clientConf);
-
-    // Delete encrypted file from the shell with trash enabled
-    // Verify the file is moved to appropriate trash within the zone
-    verifyShellDeleteWithTrash(shell, encFile1);
-
-    // Delete encryption zone from the shell with trash enabled
-    // Verify the zone is moved to appropriate trash location in user's home dir
-    verifyShellDeleteWithTrash(shell, zone1);
-  }
-
-  private void verifyShellDeleteWithTrash(FsShell shell, Path path)
-      throws Exception{
-    try {
-      final Path trashFile =
-          new Path(shell.getCurrentTrashDir(path) + "/" + path);
-      String[] argv = new String[]{"-rm", "-r", path.toString()};
-      int res = ToolRunner.run(shell, argv);
-      assertEquals("rm failed", 0, res);
-      assertTrue("File not in trash : " + trashFile, fs.exists(trashFile));
-    } catch (IOException ioe) {
-      fail(ioe.getMessage());
-    } finally {
-      if (fs.exists(path)) {
-        fs.delete(path, true);
-      }
-    }
-  }
 }
-- 
1.7.9.5

