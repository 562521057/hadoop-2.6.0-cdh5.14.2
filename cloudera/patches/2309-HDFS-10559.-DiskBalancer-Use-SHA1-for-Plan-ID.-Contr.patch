From e3d5d9787cda07b59f3a172ab6d372158e2063ac Mon Sep 17 00:00:00 2001
From: Anu Engineer <aengineer@apache.org>
Date: Mon, 15 Aug 2016 20:10:21 -0700
Subject: [PATCH 2309/2748] HDFS-10559. DiskBalancer: Use SHA1 for Plan ID.
 Contributed by Xiaobing Zhou.

(cherry picked from commit 5628b36c0872d58c9b25f23da3dab4eafad9bca3)

Conflicts:
	hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java
	hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
	hadoop-hdfs-project/hadoop-hdfs-client/src/main/proto/ClientDatanodeProtocol.proto

Change-Id: If2dda53f98ab57c04959d6da410276a1f5618278
---
 .../hdfs/protocol/ClientDatanodeProtocol.java      |    2 +-
 .../ClientDatanodeProtocolTranslatorPB.java        |    4 ++--
 .../hadoop/hdfs/server/datanode/DiskBalancer.java  |   14 +++++++-------
 .../server/diskbalancer/command/CancelCommand.java |    2 +-
 .../diskbalancer/command/ExecuteCommand.java       |    2 +-
 .../src/main/proto/ClientDatanodeProtocol.proto    |    2 +-
 .../hdfs/server/diskbalancer/TestDiskBalancer.java |    4 ++--
 .../server/diskbalancer/TestDiskBalancerRPC.java   |    2 +-
 .../TestDiskBalancerWithMockMover.java             |    8 ++++----
 9 files changed, 20 insertions(+), 20 deletions(-)

diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java
index 9e16b2c..c973450 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.java
@@ -182,7 +182,7 @@ void submitDiskBalancerPlan(String planID, long planVersion, String planFile,
   /**
    * Cancel an executing plan.
    *
-   * @param planID - A SHA512 hash of the plan string.
+   * @param planID - A SHA-1 hash of the plan string.
    */
   void cancelDiskBalancePlan(String planID) throws IOException;
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
index 19ef9ec..b998a20 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/ClientDatanodeProtocolTranslatorPB.java
@@ -377,7 +377,7 @@ public void triggerBlockReport(BlockReportOptions options)
 
   /**
    * Submits a disk balancer plan to the datanode.
-   * @param planID - Plan ID is the hash512 string of the plan that is
+   * @param planID - Plan ID is the SHA-1 string of the plan that is
    *               submitted. This is used by clients when they want to find
    *               local copies of these plans.
    * @param planVersion - The data format of the plans - for future , not
@@ -408,7 +408,7 @@ public void submitDiskBalancerPlan(String planID, long planVersion,
 
   /**
    * Cancels an executing disk balancer plan.
-   * @param planID - A SHA512 hash of the plan string.
+   * @param planID - A SHA-1 hash of the plan string.
    *
    * @throws IOException on error
    */
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
index c120d7f..4bd223f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java
@@ -156,7 +156,7 @@ private void shutdownExecutor() {
    * Takes a client submitted plan and converts into a set of work items that
    * can be executed by the blockMover.
    *
-   * @param planId      - A SHA512 of the plan string
+   * @param planId      - A SHA-1 of the plan string
    * @param planVersion - version of the plan string - for future use.
    * @param planFileName    - Plan file name
    * @param planData    - Plan data in json format
@@ -307,7 +307,7 @@ private void checkDiskBalancerEnabled()
   /**
    * Verifies that user provided plan is valid.
    *
-   * @param planID      - SHA 512 of the plan.
+   * @param planID      - SHA-1 of the plan.
    * @param planVersion - Version of the plan, for future use.
    * @param plan        - Plan String in Json.
    * @param force       - Skip verifying when the plan was generated.
@@ -344,15 +344,15 @@ private void verifyPlanVersion(long planVersion)
   }
 
   /**
-   * Verifies that plan matches the SHA512 provided by the client.
+   * Verifies that plan matches the SHA-1 provided by the client.
    *
-   * @param planID - Sha512 Hex Bytes
+   * @param planID - SHA-1 Hex Bytes
    * @param plan   - Plan String
    * @throws DiskBalancerException
    */
   private NodePlan verifyPlanHash(String planID, String plan)
       throws DiskBalancerException {
-    final long sha512Length = 128;
+    final long sha1Length = 40;
     if (plan == null || plan.length() == 0) {
       LOG.error("Disk Balancer -  Invalid plan.");
       throw new DiskBalancerException("Invalid plan.",
@@ -360,8 +360,8 @@ private NodePlan verifyPlanHash(String planID, String plan)
     }
 
     if ((planID == null) ||
-        (planID.length() != sha512Length) ||
-        !DigestUtils.sha512Hex(plan.getBytes(Charset.forName("UTF-8")))
+        (planID.length() != sha1Length) ||
+        !DigestUtils.shaHex(plan.getBytes(Charset.forName("UTF-8")))
             .equalsIgnoreCase(planID)) {
       LOG.error("Disk Balancer - Invalid plan hash.");
       throw new DiskBalancerException("Invalid or mis-matched hash.",
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java
index e0c6566..007272e 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java
@@ -94,7 +94,7 @@ private void cancelPlan(String planData) throws IOException {
     String dataNodeAddress = plan.getNodeName() + ":" + plan.getPort();
     Preconditions.checkNotNull(dataNodeAddress);
     ClientDatanodeProtocol dataNode = getDataNodeProxy(dataNodeAddress);
-    String planHash = DigestUtils.sha512Hex(planData);
+    String planHash = DigestUtils.shaHex(planData);
     try {
       dataNode.cancelDiskBalancePlan(planHash);
     } catch (DiskBalancerException ex) {
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java
index ac53bce..3a348c9 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.java
@@ -86,7 +86,7 @@ private void submitPlan(final String planFile, final String planData)
     String dataNodeAddress = plan.getNodeName() + ":" + plan.getPort();
     Preconditions.checkNotNull(dataNodeAddress);
     ClientDatanodeProtocol dataNode = getDataNodeProxy(dataNodeAddress);
-    String planHash = DigestUtils.sha512Hex(planData);
+    String planHash = DigestUtils.shaHex(planData);
     try {
       // TODO : Support skipping date check.
       dataNode.submitDiskBalancerPlan(planHash, DiskBalancerCLI.PLAN_VERSION,
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientDatanodeProtocol.proto b/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientDatanodeProtocol.proto
index 929d235..7bcd18f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientDatanodeProtocol.proto
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/ClientDatanodeProtocol.proto
@@ -168,7 +168,7 @@ message TriggerBlockReportResponseProto {
  * balancer plan to a data node.
  */
 message SubmitDiskBalancerPlanRequestProto {
-  required string planID = 1;         // A hash of the plan like SHA512
+  required string planID = 1;         // A hash of the plan like SHA-1
   required string plan = 2;           // Plan file data in Json format
   optional uint64 planVersion = 3;    // Plan version number
   optional bool ignoreDateCheck = 4;  // Ignore date checks on this plan.
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java
index 9a73d14..6cf64fb 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancer.java
@@ -187,7 +187,7 @@ public void TestDiskBalancerEndToEnd() throws Exception {
       plan.setNodeUUID(dnNode.getDatanodeUuid());
       plan.setTimeStamp(Time.now());
       String planJson = plan.toJson();
-      String planID = DigestUtils.sha512Hex(planJson);
+      String planID = DigestUtils.shaHex(planJson);
       assertNotNull(plan.getVolumeSetPlans());
       assertTrue(plan.getVolumeSetPlans().size() > 0);
       plan.getVolumeSetPlans().get(0).setTolerancePercent(10);
@@ -304,7 +304,7 @@ public void testBalanceDataBetweenMultiplePairsOfVolumes()
       plan.setNodeUUID(dnNode.getDatanodeUuid());
       plan.setTimeStamp(Time.now());
       String planJson = plan.toJson();
-      String planID = DigestUtils.sha512Hex(planJson);
+      String planID = DigestUtils.shaHex(planJson);
 
       dataNode.submitDiskBalancerPlan(planID, 1, PLAN_FILE, planJson, false);
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
index 8e520fb..8472f05 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerRPC.java
@@ -314,7 +314,7 @@ public RpcTestHelper invoke() throws Exception {
       plan = new NodePlan(node.getDataNodeName(), node.getDataNodePort());
       planner.balanceVolumeSet(node, node.getVolumeSets().get("DISK"), plan);
       planVersion = 1;
-      planHash = DigestUtils.sha512Hex(plan.toJson());
+      planHash = DigestUtils.shaHex(plan.toJson());
       return this;
     }
   }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java
index d58a1fa..7dafe2f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestDiskBalancerWithMockMover.java
@@ -122,7 +122,7 @@ public void testDiskBalancerEnabled() throws DiskBalancerException {
   private void executeSubmitPlan(NodePlan plan, DiskBalancer balancer,
                                  int version) throws IOException {
     String planJson = plan.toJson();
-    String planID = DigestUtils.sha512Hex(planJson);
+    String planID = DigestUtils.shaHex(planJson);
     balancer.submitPlan(planID, version, PLAN_FILE, planJson, false);
   }
 
@@ -211,7 +211,7 @@ public void testSubmitWithNullPlan() throws Exception {
     NodePlan plan = mockMoverHelper.getPlan();
     DiskBalancer balancer = mockMoverHelper.getBalancer();
     String planJson = plan.toJson();
-    String planID = DigestUtils.sha512Hex(planJson);
+    String planID = DigestUtils.shaHex(planJson);
 
     thrown.expect(DiskBalancerException.class);
     thrown.expect(new DiskBalancerResultVerifier(DiskBalancerException
@@ -228,7 +228,7 @@ public void testSubmitWithInvalidHash() throws Exception {
 
 
     String planJson = plan.toJson();
-    String planID = DigestUtils.sha512Hex(planJson);
+    String planID = DigestUtils.shaHex(planJson);
     char repChar = planID.charAt(0);
     repChar++;
 
@@ -258,7 +258,7 @@ public void testCancelDiskBalancerPlan() throws Exception {
 
 
     String planJson = plan.toJson();
-    String planID = DigestUtils.sha512Hex(planJson);
+    String planID = DigestUtils.shaHex(planJson);
     balancer.cancelPlan(planID);
 
     DiskBalancerWorkStatus status = balancer.queryWorkStatus();
-- 
1.7.9.5

